
# ğŸ›¡ï¸ Fraud Detection Project - Adey Innovations Inc.

## ğŸ“Œ Overview

This project aims to build robust, interpretable machine learning models to detect fraudulent activities in e-commerce and banking transactions. The core objectives include:

* Enhancing fraud detection accuracy.
* Tackling class imbalance effectively.
* Engineering meaningful and insightful features.
* Maintaining a balance between security and user experience.

---

## ğŸ“ Project Structure

```
fraud-detection-project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original datasets (e.g., Fraud_Data.csv, IpAddress_to_Country.csv)
â”‚   â””â”€â”€ processed/               # Cleaned, feature-engineered, and preprocessed datasets
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ preprocessor.py      # Preprocessing pipeline: cleaning, encoding, scaling, and balancing
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ train_models.py      # Model training and evaluation logic (coming soon)
â”‚   â”‚
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ 01_eda_fraud_data.ipynb   # EDA and feature engineering notebook
â”‚
â”œâ”€â”€ reports/                     # Visualizations, analysis results, and project reports
â”œâ”€â”€ requirements.txt             # Project dependencies
â””â”€â”€ README.md                    # Project documentation (this file)
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone <your-repo-url>
cd fraud-detection-project
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
# macOS/Linux
source venv/bin/activate
# Windows
venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ How to Use

### ğŸ”§ Preprocess the Data

Run the preprocessing pipeline to clean, encode, scale, and balance your dataset:

```bash
python src/utils/preprocessor.py
```

* Inputs: `data/raw/Fraud_Data.csv`
* Outputs: `data/processed/processed_fraud_data.csv`
* Includes: datetime handling, SMOTE oversampling, encoding (with high-cardinality management), and scaling

---

### ğŸ“Š Exploratory Data Analysis

Launch the EDA notebook:

```bash
jupyter notebook src/notebooks/01_eda_fraud_data.ipynb
```

* Understand feature distributions, trends, and anomalies
* Engineer features like:

  * Time since signup/login
  * IP-to-country mapping
  * Device/browser indicators

---

### ğŸ§  Model Training *(Coming Soon)*

* Will include training with:

  * Logistic Regression
  * Random Forest
  * LightGBM
* Evaluation with:

  * AUC-PR
  * F1-score
* Explanation with:

  * SHAP (model interpretability)

---

## âœ¨ Key Features

* âœ… **Class Imbalance Handling:** SMOTE + undersampling
* ğŸ” **Feature Engineering:** Time-based, geolocation, and behavior-derived features
* ğŸ§± **Modular Architecture:** Clean separation of code components
* ğŸ§  **Explainability-First:** SHAP integration for interpretability (planned)

---

## ğŸ“¦ Requirements

* Python 3.8+
* `pandas`, `scikit-learn`, `imbalanced-learn`
* `matplotlib`, `seaborn`
* `jupyter`

See full list in `requirements.txt`.

---

## âš ï¸ Notes

* High-cardinality columns (e.g., `user_id`, `ip_address`) are dropped to reduce memory usage.
* Avoid applying SMOTE on the test set to prevent data leakage.
* The modeling component is still under development.

---
